"""æ–°é—»èˆ†æƒ…å·¥å…· - çƒ­é—¨æ–°é—»ã€KOL è§‚ç‚¹ã€è¶‹åŠ¿è¯é¢˜ã€å¸ç§æ–°é—»ã€çªå‘æ¶ˆæ¯ + æ‰¹é‡å¸ç§èˆ†æƒ…"""

import asyncio
from collections import deque
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Any

from getall.agent.tools.base import Tool
from getall.trading.data.hub import DataHub
from getall.trading.news_cache import (
    iter_history_snapshots,
    load_last_non_empty_snapshot,
    load_latest_snapshot,
    persist_news_snapshot,
    pick_best_snapshot,
    snapshot_has_content,
    snapshot_ts,
)


class NewsSentimentTool(Tool):
    """ä»Ž Followin API å’Œ bwenews ç¼“å­˜èŽ·å–åŠ å¯†è´§å¸æ–°é—»ä¸Žèˆ†æƒ…æ•°æ®ã€‚
    æ”¯æŒ batch_coin_sentiment æ‰¹é‡æ“ä½œï¼Œä¸€æ¬¡èŽ·å–å¤šä¸ªå¸ç§çš„æ–°é—»+KOL è§‚ç‚¹ã€‚
    """

    def __init__(self, hub: DataHub, workspace_path: Path | None = None):
        # æ³¨å…¥ DataHubï¼Œé€šè¿‡ followin é€‚é…å™¨èŽ·å–æ–°é—»æ•°æ®
        self.hub = hub
        self.workspace_path = workspace_path
        # latest_news å¢žé‡åŽ»é‡ç¼“å­˜ï¼ˆè¿›ç¨‹å†…ï¼›é¿å…é‡å¤æ’­æŠ¥åŒä¸€æ¡æ–°é—»ï¼‰
        self._latest_seen: deque[str] = deque()
        self._latest_seen_set: set[str] = set()
        self._latest_seen_max = 500

    @property
    def name(self) -> str:
        return "news_sentiment"

    @property
    def description(self) -> str:
        return (
            "Get crypto news, KOL opinions, trending topics (ä»Šæ—¥æœ€æ–°çƒ­ç‚¹), and breaking "
            "news from Followin API and bwenews cache.\n"
            "Supports batch_coin_sentiment: get news + KOL opinions for "
            "multiple coins in one call (ideal for cron news-feed tasks).\n"
            "Use action='latest_news' for continuously updating important/latest news (æœ€æ–°æ–°é—», å¢žé‡åŽ»é‡).\n"
            "Use action='trending_topics' (or 'hot_events') to get today's hottest topics (çƒ­é—¨äº‹ä»¶/é£Žå‘æ ‡)."
        )

    @property
    def parameters(self) -> dict[str, Any]:
        return {
            "type": "object",
            "properties": {
                "action": {
                    "type": "string",
                    "description": "The type of news/sentiment data to fetch",
                    "enum": [
                        "batch_coin_sentiment",  # æ‰¹é‡: å¤šå¸ç§æ–°é—»+KOL
                        "recent",           # ä»Žæœ¬åœ°ç¼“å­˜è¿”å›žæœ€è¿‘æ–°é—»ï¼ˆå¯æŒ‰çª—å£ç­›é€‰ï¼Œç©ºç»“æžœè‡ªåŠ¨å›žé€€ï¼‰
                        "latest_news",      # æœ€æ–°æ–°é—»ï¼ˆå¢žé‡ï¼Œä¼˜å…ˆ importantï¼‰
                        "trending_news",    # çƒ­é—¨æ–°é—»
                        "kol_opinions",     # KOL è§‚ç‚¹
                        "hot_events",       # çƒ­é—¨äº‹ä»¶ï¼ˆåˆ«åï¼štrending_topicsï¼‰
                        "trending_topics",  # çƒ­é—¨è¯é¢˜ï¼ˆä»Šæ—¥æœ€æ–°çƒ­ç‚¹/é£Žå‘æ ‡ï¼‰
                        "coin_news",        # å¸ç§ä¸“å±žæ–°é—»
                        "breaking_news",    # çªå‘æ¶ˆæ¯
                    ],
                },
                "symbol": {
                    "type": "string",
                    "description": (
                        "Coin symbol, e.g. 'BTC'. Required for kol_opinions and coin_news; "
                        "optional for latest_news (filters to that coin)."
                    ),
                },
                "symbols": {
                    "type": "string",
                    "description": (
                        "Comma-separated coin symbols for batch_coin_sentiment, e.g. 'BTC,ETH,SOL'. "
                        "Fetches KOL opinions + coin news for each symbol."
                    ),
                },
                "count": {
                    "type": "integer",
                    "description": "Number of results per category (default: 5 for batch, 10 for single)",
                    "minimum": 1,
                    "maximum": 50,
                },
                "window_minutes": {
                    "type": "integer",
                    "description": "For action='recent': time window in minutes to search cache history (default: 360).",
                    "minimum": 1,
                    "maximum": 43200,
                },
                "mode": {
                    "type": "string",
                    "description": (
                        "For action='recent': "
                        "'auto' uses cache if fresh else fetches live; "
                        "'cache' never fetches live; "
                        "'live' always fetches live then caches."
                    ),
                    "enum": ["auto", "cache", "live"],
                },
                "prefer_non_empty": {
                    "type": "boolean",
                    "description": "For action='recent': if true, avoid returning empty cache snapshots (default: true).",
                },
            },
            "required": ["action"],
        }

    async def execute(self, **kwargs: Any) -> str:
        action: str = kwargs["action"]
        symbol: str | None = kwargs.get("symbol")
        symbols_str: str | None = kwargs.get("symbols")
        count: int = kwargs.get("count", 10)
        window_minutes: int = kwargs.get("window_minutes", 360)
        mode: str = kwargs.get("mode", "auto")
        prefer_non_empty: bool = kwargs.get("prefer_non_empty", True)

        try:
            # â”€â”€ æ‰¹é‡æ“ä½œ â”€â”€
            if action == "batch_coin_sentiment":
                return await self._batch_coin_sentiment(
                    symbols_str=symbols_str or "",
                    count=kwargs.get("count", 5),  # æ‰¹é‡é»˜è®¤æ¯ä¸ªå¸ 5 æ¡
                )
            if action == "recent":
                return await self._recent(
                    symbols_str=symbols_str or "",
                    count=kwargs.get("count", 5),
                    window_minutes=window_minutes,
                    mode=mode,
                    prefer_non_empty=prefer_non_empty,
                )

            handlers = {
                "latest_news": self._latest_news,
                "trending_news": self._trending_news,
                "kol_opinions": self._kol_opinions,
                "hot_events": self._trending_topics,  # alias
                "trending_topics": self._trending_topics,
                "coin_news": self._coin_news,
                "breaking_news": self._breaking_news,
            }
            handler = handlers.get(action)
            if handler is None:
                return f"Error: unknown action '{action}'"
            return await handler(symbol=symbol, count=count)
        except Exception as e:
            return f"Error fetching {action}: {e}"

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # é€šç”¨è§£æžï¼šå…¼å®¹ Followin å¤šç§è¿”å›žç»“æž„
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @staticmethod
    def _extract_list_payload(data: Any) -> tuple[list[dict[str, Any]], str | None]:
        """
        Normalize Followin payload to a list of dict items.

        Followin endpoints may return:
        - list[dict]
        - {"list": [...]}
        - {"items": [...]}
        - {"data": {"list": [...]}} (depending on gateway/proxy)
        - {"error": "..."} (our adapter error shape)
        """
        if data is None:
            return [], None

        if isinstance(data, dict) and data.get("error"):
            return [], str(data.get("error"))

        if isinstance(data, list):
            return [x for x in data if isinstance(x, dict)], None

        if isinstance(data, dict):
            for key in ("list", "items", "result", "rows"):
                val = data.get(key)
                if isinstance(val, list):
                    return [x for x in val if isinstance(x, dict)], None

            # å…¼å®¹ä¸€å±‚åµŒå¥—
            for key in ("data", "payload"):
                nested = data.get(key)
                if isinstance(nested, dict):
                    for k2 in ("list", "items", "result", "rows"):
                        val = nested.get(k2)
                        if isinstance(val, list):
                            return [x for x in val if isinstance(x, dict)], None

        return [], None

    @staticmethod
    def _news_uid(item: dict[str, Any]) -> str:
        """Best-effort stable uid for deduplication."""
        for k in ("id", "newsId", "feedId", "uuid"):
            v = item.get(k)
            if v:
                return f"{k}:{v}"
        url = item.get("url") or item.get("page_url") or item.get("pageUrl") or item.get("link")
        if url:
            return f"url:{url}"
        title = item.get("title") or item.get("headline") or ""
        ts = (
            item.get("publishedAt")
            or item.get("timestamp")
            or item.get("publish_time")
            or item.get("publishTime")
            or item.get("published_at")
            or ""
        )
        src = item.get("source") or item.get("source_name") or item.get("sourceName") or ""
        return f"fallback:{src}|{ts}|{title}"

    @staticmethod
    def _looks_important(item: dict[str, Any]) -> bool:
        """
        Determine whether a news item is important.

        Supports common fields:
        - important: bool/int/str
        - importance: "high"/"medium"/"low"
        - level: same as above
        - type/category: may contain "important"
        """
        if "important" in item:
            v = item.get("important")
            if isinstance(v, bool):
                return v
            if isinstance(v, (int, float)):
                return v > 0
            if isinstance(v, str):
                return v.strip().lower() in ("1", "true", "yes", "y", "important", "high")

        for k in ("importance", "level", "priority"):
            v = item.get(k)
            if isinstance(v, str):
                return v.strip().lower() in ("high", "important", "urgent")
            if isinstance(v, (int, float)):
                return v >= 2

        for k in ("type", "category"):
            v = item.get(k)
            if isinstance(v, str) and "important" in v.lower():
                return True

        return False

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # æ‰¹é‡å¸ç§èˆ†æƒ…
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _batch_coin_sentiment(self, symbols_str: str, count: int) -> str:
        """æ‰¹é‡èŽ·å–å¤šå¸ç§çš„ KOL è§‚ç‚¹ + å¸ç§æ–°é—» (cron:news-feed ä¸“ç”¨).

        åŒæ—¶æŠ“å–å…¨å¸‚åœº trending news å’Œ trending topics (ä¸æŒ‰å¸ç§è¿‡æ»¤),
        å†æŒ‰æ¯ä¸ªå¸ç§å¹¶å‘èŽ·å– KOL opinions,
        ä¸€æ¬¡ tool call è¿”å›žå®Œæ•´èˆ†æƒ…å¿«ç…§.
        """
        symbols = [s.strip().upper() for s in symbols_str.split(",") if s.strip()]
        if not symbols:
            return "Error: 'symbols' is required for batch_coin_sentiment, e.g. 'BTC,ETH,SOL'"

        sem = asyncio.Semaphore(4)

        # 1. å…¨å¸‚åœºæ–°é—» + çƒ­é—¨è¯é¢˜ (ä¸Žå¸ç§æŸ¥è¯¢å¹¶å‘æ‰§è¡Œ)
        trending_coro = self.hub.followin.get_trending_news(count=count * 2)
        topics_coro = self.hub.followin.get_trending_topics(count=5)

        # 2. æ¯ä¸ªå¸ç§çš„ KOL è§‚ç‚¹
        kol_results: dict[str, Any] = {}

        async def _fetch_kol(sym: str) -> None:
            async with sem:
                try:
                    kol_results[sym] = await self.hub.followin.get_kol_opinions(
                        symbol=sym, count=count
                    )
                except Exception as e:
                    kol_results[sym] = {"error": str(e)}

        # å¹¶å‘æ‰§è¡Œå…¨éƒ¨
        all_tasks = [_fetch_kol(s) for s in symbols]
        trending_task = asyncio.ensure_future(trending_coro)
        topics_task = asyncio.ensure_future(topics_coro)
        await asyncio.gather(*all_tasks, trending_task, topics_task, return_exceptions=True)

        def _task_result(task: asyncio.Future, default: Any) -> Any:
            if task.cancelled():
                return default
            try:
                return task.result()
            except Exception:
                return default

        trending_data = _task_result(trending_task, [])
        topics_data = _task_result(topics_task, [])

        # â”€â”€ Persist cache snapshot (code-level guarantee) â”€â”€
        snapshot = self._build_batch_snapshot(
            symbols=symbols,
            count=count,
            trending_data=trending_data,
            topics_data=topics_data,
            kol_results=kol_results,
        )
        self._persist_snapshot(snapshot)

        # æ ¼å¼åŒ–è¾“å‡º
        lines = [f"ðŸ“° Batch Sentiment Report ({len(symbols)} coins)"]
        lines.append("â•" * 60)

        # å…¨å¸‚åœºçƒ­é—¨æ–°é—»
        lines.append("\nðŸ”¥ Trending News:")
        normalized = snapshot.get("data") if isinstance(snapshot, dict) else {}
        trending_news = (
            normalized.get("trending_news") if isinstance(normalized, dict) else None
        )
        topics_flat = (
            normalized.get("trending_topics") if isinstance(normalized, dict) else None
        )
        kol_norm = normalized.get("kol_opinions") if isinstance(normalized, dict) else None
        errors = snapshot.get("errors") if isinstance(snapshot, dict) else None

        if isinstance(trending_news, list) and trending_news:
            for i, item in enumerate(trending_news[:8], 1):
                if not isinstance(item, dict):
                    lines.append(f"  {i}. {str(item)[:100]}")
                    continue
                title = (
                    item.get("title")
                    or item.get("translated_title")
                    or item.get("headline")
                    or "Untitled"
                )
                source = (
                    item.get("source")
                    or item.get("source_name")
                    or item.get("sourceName")
                    or ""
                )
                ts = self._format_time(
                    item.get("publishedAt")
                    or item.get("timestamp")
                    or item.get("publish_time")
                    or item.get("publishTime")
                    or item.get("published_at")
                )
                lines.append(f"  {i}. {str(title)[:100]}")
                if source or ts:
                    lines.append(f"     [{source}] {ts}")
        else:
            err = errors.get("trending_news") if isinstance(errors, dict) else None
            if err:
                lines.append(f"  âŒ {err}")
            else:
                lines.append("  No trending news available.")

        # çƒ­é—¨è¯é¢˜
        lines.append("\nðŸ“ˆ Trending Topics:")
        if isinstance(topics_flat, list) and topics_flat:
            for item in topics_flat[:5]:
                topic = (
                    item.get("topic", item.get("title", "?"))
                    if isinstance(item, dict)
                    else str(item)
                )
                heat = (
                    item.get("heat", item.get("score", ""))
                    if isinstance(item, dict)
                    else ""
                )
                lines.append(f"  â€¢ {topic}" + (f" (heat: {heat})" if heat else ""))
        else:
            err = errors.get("trending_topics") if isinstance(errors, dict) else None
            if err:
                lines.append(f"  âŒ {err}")
            else:
                lines.append("  No trending topics available.")

        # æ¯ä¸ªå¸ç§çš„ KOL è§‚ç‚¹
        for sym in symbols:
            lines.append(f"\nâ”€â”€ {sym} KOL Opinions â”€â”€")
            kol_data = kol_norm.get(sym) if isinstance(kol_norm, dict) else None
            kol_errors = errors.get("kol_opinions") if isinstance(errors, dict) else None
            if isinstance(kol_errors, dict) and sym in kol_errors:
                lines.append(f"  âŒ {kol_errors[sym]}")
            elif isinstance(kol_data, list) and kol_data:
                bullish = 0
                bearish = 0
                for item in kol_data[:count]:
                    author = item.get("author", item.get("kolName", "?"))
                    sentiment = item.get("sentiment", "neutral")
                    content = item.get("content", item.get("text", ""))
                    truncated = content[:100] + "..." if len(content) > 100 else content

                    if sentiment in ("bullish", "positive", "long"):
                        bullish += 1
                        tag = "ðŸŸ¢"
                    elif sentiment in ("bearish", "negative", "short"):
                        bearish += 1
                        tag = "ðŸ”´"
                    else:
                        tag = "âšª"

                    lines.append(f"  {tag} @{author}: {truncated}")
                total = bullish + bearish + (len(kol_data[:count]) - bullish - bearish)
                lines.append(f"  Summary: ðŸŸ¢{bullish} ðŸ”´{bearish} / {total} total")
            else:
                lines.append("  No KOL opinions found.")

        lines.append(f"\n{'â•' * 60}")
        lines.append(f"Coins: {', '.join(symbols)} | Per-coin limit: {count}")
        return "\n".join(lines)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Cache snapshot helpers (batch â†’ latest/history/last_non_empty)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _build_batch_snapshot(
        self,
        *,
        symbols: list[str],
        count: int,
        trending_data: Any,
        topics_data: Any,
        kol_results: dict[str, Any],
    ) -> dict[str, Any]:
        ts = datetime.now(timezone.utc).isoformat()

        trending_news, trending_err = self._extract_list_payload(trending_data)

        # Normalize trending topics to a flat list of topic dicts.
        topics_err: str | None = None
        topics: list[dict[str, Any]] = []
        if isinstance(topics_data, dict) and topics_data.get("error"):
            topics_err = str(topics_data.get("error"))
        elif isinstance(topics_data, dict) and "list" in topics_data:
            for day_group in topics_data.get("list", []) or []:
                if isinstance(day_group, dict):
                    day_topics = day_group.get("topics") or []
                    if isinstance(day_topics, list):
                        topics.extend([x for x in day_topics if isinstance(x, dict)])
        elif isinstance(topics_data, list):
            topics = [x for x in topics_data if isinstance(x, dict)]
        else:
            topics, topics_err = self._extract_list_payload(topics_data)

        kol_opinions: dict[str, list[dict[str, Any]]] = {}
        kol_errors: dict[str, str] = {}
        for sym in symbols:
            lst, err = self._extract_list_payload(kol_results.get(sym))
            kol_opinions[sym] = lst
            if err:
                kol_errors[sym] = err

        snapshot: dict[str, Any] = {
            "ts": ts,
            "source": "news_sentiment.batch_coin_sentiment",
            "symbols": list(symbols),
            "count": count,
            "data": {
                "trending_news": trending_news,
                "trending_topics": topics,
                "kol_opinions": kol_opinions,
            },
        }

        errors: dict[str, Any] = {}
        if trending_err:
            errors["trending_news"] = trending_err
        if topics_err:
            errors["trending_topics"] = topics_err
        if kol_errors:
            errors["kol_opinions"] = kol_errors
        if errors:
            snapshot["errors"] = errors

        snapshot["has_content"] = snapshot_has_content(snapshot)
        return snapshot

    def _persist_snapshot(self, snapshot: dict[str, Any]) -> None:
        if not self.workspace_path:
            return
        try:
            persist_news_snapshot(self.workspace_path, snapshot)
        except Exception:
            # Never break tool output due to cache persistence failures.
            return

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Recent (cache-first) query
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _recent(
        self,
        *,
        symbols_str: str,
        count: int,
        window_minutes: int,
        mode: str,
        prefer_non_empty: bool,
    ) -> str:
        symbols = [s.strip().upper() for s in symbols_str.split(",") if s.strip()]
        if not symbols:
            return "Error: 'symbols' is required for recent, e.g. 'BTC,ETH,SOL'"
        if not self.workspace_path:
            return "Error: news cache is not configured (workspace_path missing)."

        now = datetime.now(timezone.utc)
        since = now - timedelta(minutes=window_minutes)

        mode_norm = (mode or "auto").strip().lower()
        if mode_norm not in ("auto", "cache", "live"):
            mode_norm = "auto"

        # â”€â”€ Decide whether to fetch live â”€â”€
        cache_ttl_minutes = 20  # cron default is 15m; keep a small buffer
        latest = load_latest_snapshot(self.workspace_path)
        latest_dt = snapshot_ts(latest) if isinstance(latest, dict) else None
        is_fresh = bool(latest_dt and (now - latest_dt).total_seconds() <= cache_ttl_minutes * 60)

        # If the latest snapshot does not cover requested symbols, treat as stale for auto-mode.
        if is_fresh and isinstance(latest, dict):
            cached_syms = set(latest.get("symbols") or [])
            if not set(symbols).issubset(cached_syms):
                is_fresh = False

        if mode_norm == "live" or (mode_norm == "auto" and not is_fresh):
            # Fetch fresh snapshot and persist (batch handler already persists)
            await self._batch_coin_sentiment(symbols_str=",".join(symbols), count=count)

        # â”€â”€ Pick best snapshot from history within the window â”€â”€
        snapshots = list(iter_history_snapshots(self.workspace_path, since=since))

        wanted = set(symbols)
        covering = [
            s for s in snapshots
            if isinstance(s, dict) and wanted.issubset(set(s.get("symbols") or []))
        ]
        if covering:
            snapshots = covering

        picked = pick_best_snapshot(snapshots, prefer_non_empty=prefer_non_empty)
        fallback_note = ""

        if picked is None or (prefer_non_empty and not snapshot_has_content(picked)):
            last_good = load_last_non_empty_snapshot(self.workspace_path)
            if isinstance(last_good, dict):
                picked = last_good
                dt = snapshot_ts(picked)
                ts_str = dt.isoformat() if dt else (picked.get("ts") or "?")
                fallback_note = (
                    f"\n[Note] No non-empty cache snapshot in last {window_minutes}m; "
                    f"showing last non-empty snapshot @ {ts_str}."
                )

        if not isinstance(picked, dict):
            return "ðŸ“° No cached news snapshots available yet."

        picked_dt = snapshot_ts(picked)
        picked_ts = picked_dt.isoformat() if picked_dt else (picked.get("ts") or "unknown")
        data = picked.get("data") if isinstance(picked.get("data"), dict) else {}
        trending_news = data.get("trending_news") if isinstance(data.get("trending_news"), list) else []
        trending_topics = data.get("trending_topics") if isinstance(data.get("trending_topics"), list) else []
        kol = data.get("kol_opinions") if isinstance(data.get("kol_opinions"), dict) else {}

        lines: list[str] = []
        lines.append(f"ðŸ“° Recent News (cache window: {window_minutes}m)")
        lines.append(f"Snapshot: {picked_ts}")
        lines.append("â•" * 60)

        lines.append("\nðŸ”¥ Trending News:")
        if trending_news:
            for i, item in enumerate(trending_news[:8], 1):
                if not isinstance(item, dict):
                    lines.append(f"  {i}. {str(item)[:120]}")
                    continue
                title = (
                    item.get("title")
                    or item.get("translated_title")
                    or item.get("headline")
                    or "Untitled"
                )
                source = item.get("source") or item.get("source_name") or item.get("sourceName") or ""
                tss = self._format_time(
                    item.get("publishedAt")
                    or item.get("timestamp")
                    or item.get("publish_time")
                    or item.get("publishTime")
                    or item.get("published_at")
                )
                lines.append(f"  {i}. {str(title)[:100]}")
                if source or tss:
                    lines.append(f"     [{source}] {tss}")
        else:
            lines.append("  No trending news available.")

        lines.append("\nðŸ“ˆ Trending Topics:")
        if trending_topics:
            for item in trending_topics[:5]:
                if not isinstance(item, dict):
                    lines.append(f"  â€¢ {str(item)[:120]}")
                    continue
                topic = item.get("topic") or item.get("title") or "?"
                heat = item.get("heat") or item.get("score") or ""
                lines.append(f"  â€¢ {topic}" + (f" (heat: {heat})" if heat else ""))
        else:
            lines.append("  No trending topics available.")

        for sym in symbols:
            lines.append(f"\nâ”€â”€ {sym} KOL Opinions â”€â”€")
            k = kol.get(sym)
            if isinstance(k, list) and k:
                for item in k[:count]:
                    if not isinstance(item, dict):
                        lines.append(f"  â€¢ {str(item)[:120]}")
                        continue
                    author = item.get("author", item.get("kolName", "?"))
                    sentiment = item.get("sentiment", "neutral")
                    content = item.get("content", item.get("text", ""))
                    truncated = content[:100] + "..." if len(content) > 100 else content
                    if sentiment in ("bullish", "positive", "long"):
                        tag = "ðŸŸ¢"
                    elif sentiment in ("bearish", "negative", "short"):
                        tag = "ðŸ”´"
                    else:
                        tag = "âšª"
                    lines.append(f"  {tag} @{author}: {truncated}")
            else:
                lines.append("  No KOL opinions found.")

        if fallback_note:
            lines.append(fallback_note)

        return "\n".join(lines)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # æœ€æ–°æ–°é—»ï¼ˆå¢žé‡ï¼‰
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _latest_news(self, symbol: str | None, count: int, **_) -> str:
        """
        èŽ·å–â€œæœ€æ–°æ–°é—»â€ï¼šæ”¯æŒå¢žé‡åŽ»é‡ï¼Œå¹¶åœ¨è¿”å›žå­˜åœ¨ important å­—æ®µæ—¶ä¼˜å…ˆç­›é€‰é‡è¦æ–°é—»ã€‚

        ä¸šåŠ¡è¯­ä¹‰ï¼š
        - latest_newsï¼šé¢å‘â€œæ–°é—»æµâ€ï¼Œéšæ—¶é—´æŒç»­æ›´æ–°ï¼›é€‚åˆé¢‘ç¹æŸ¥è¯¢
        - trending_topics/hot_eventsï¼šé¢å‘â€œçƒ­ç‚¹äº‹ä»¶/è¯é¢˜â€ï¼Œæ›´æ–°é¢‘çŽ‡è¾ƒä½Žï¼ˆä¸€å¤© 1~2 æ¡ï¼‰
        """
        fetch_count = min(max(count * 3, count), 50)
        scope = "GLOBAL"
        if symbol:
            clean_symbol = self._clean_symbol(symbol)
            scope = clean_symbol
            raw = await self.hub.followin.get_coin_news(symbol=clean_symbol, count=fetch_count)
        else:
            raw = await self.hub.followin.get_trending_news(count=fetch_count)
        data, err = self._extract_list_payload(raw)
        if err:
            return f"âŒ Error fetching latest news: {err}"
        if not data:
            return "ðŸ†• No latest news available at the moment."

        # å°½é‡æŒ‰æ—¶é—´å€’åºå±•ç¤º
        try:
            data.sort(
                key=lambda x: (
                    x.get("publishedAt")
                    or x.get("timestamp")
                    or x.get("publish_time")
                    or x.get("publishTime")
                    or x.get("published_at")
                    or 0
                ),
                reverse=True,
            )
        except Exception:
            pass

        def _scoped_uid(item: dict[str, Any]) -> str:
            return f"{scope}:{self._news_uid(item)}"

        # å¦‚æžœè¿”å›žé‡Œå­˜åœ¨ important/importance å­—æ®µ â†’ åªæ˜¾ç¤ºâ€œé‡è¦æ–°é—»â€
        has_importance_field = any(
            any(k in item for k in ("important", "importance", "level", "priority"))
            for item in data
        )
        candidates = [x for x in data if self._looks_important(x)] if has_importance_field else data

        # è®¡ç®—â€œæœ¬æ¬¡æ–°å¢žâ€ï¼ˆåœ¨æ›´æ–°åŽ»é‡é›†åˆä¹‹å‰ï¼‰
        items_to_show = candidates[:count]
        new_uids: set[str] = set()
        for x in items_to_show:
            uid = _scoped_uid(x)
            if uid not in self._latest_seen_set:
                new_uids.add(uid)

        # è®°ä½æœ¬æ¬¡æ‹‰åˆ°çš„æ‰€æœ‰æ–°é—»ï¼ˆä¸è®ºæ˜¯å¦ importantï¼‰ï¼Œé¿å…ä¸‹ä¸€æ¬¡é‡å¤ç»Ÿè®¡
        for item in data:
            uid = _scoped_uid(item)
            if uid in self._latest_seen_set:
                continue
            self._latest_seen.append(uid)
            self._latest_seen_set.add(uid)
            while len(self._latest_seen) > self._latest_seen_max:
                old = self._latest_seen.popleft()
                self._latest_seen_set.discard(old)

        if not items_to_show:
            if has_importance_field:
                return "ðŸ†• No important news available at the moment."
            return "ðŸ†• No latest news available at the moment."

        title = "ðŸ†• æœ€æ–°æ–°é—»ï¼ˆå¢žé‡ï¼‰" if scope == "GLOBAL" else f"ðŸ†• {scope} æœ€æ–°æ–°é—»ï¼ˆå¢žé‡ï¼‰"
        if has_importance_field:
            title += "ï½œä»…é‡è¦"
        lines = [title]
        lines.append("â•" * 60)
        lines.append(
            f"æœ¬æ¬¡æ–°å¢ž {len(new_uids)} æ¡ï½œæ˜¾ç¤º {len(items_to_show)} æ¡ï¼ˆæ‹‰å– {fetch_count} æ¡åŽ»é‡ï¼‰\n"
        )

        for i, item in enumerate(items_to_show, 1):
            headline = (
                item.get("title")
                or item.get("translated_title")
                or item.get("headline")
                or "Untitled"
            )
            source = (
                item.get("source")
                or item.get("source_name")
                or item.get("sourceName")
                or "Unknown"
            )
            published = self._format_time(
                item.get("publishedAt")
                or item.get("timestamp")
                or item.get("publish_time")
                or item.get("publishTime")
                or item.get("published_at")
            )
            summary = (
                item.get("summary")
                or item.get("description")
                or item.get("content")
                or item.get("translated_content")
                or ""
            )
            url = item.get("url") or item.get("page_url") or item.get("pageUrl") or item.get("link") or ""

            prefix = "ðŸ†• " if _scoped_uid(item) in new_uids else ""
            lines.append(f"{i}. {prefix}{headline}")
            lines.append(f"   Source: {source} | {published}")
            if summary:
                truncated = summary[:200] + "..." if len(summary) > 200 else summary
                lines.append(f"   {truncated}")
            if url:
                lines.append(f"   Link: {url}")
            lines.append("")

        return "\n".join(lines).rstrip()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # çƒ­é—¨æ–°é—»
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _trending_news(self, count: int, **_) -> str:
        """èŽ·å–å½“å‰çƒ­é—¨åŠ å¯†è´§å¸æ–°é—»"""
        raw = await self.hub.followin.get_trending_news(count=count)
        data, err = self._extract_list_payload(raw)
        if err:
            return f"âŒ Error fetching trending news: {err}"
        if not data:
            return "ðŸ“° No trending news available at the moment."

        lines = [f"ðŸ“° Trending Crypto News (top {count})"]
        lines.append("â•" * 50)

        # å°½é‡æŒ‰æ—¶é—´å€’åºå±•ç¤º
        try:
            data.sort(
                key=lambda x: (
                    x.get("publishedAt")
                    or x.get("timestamp")
                    or x.get("publish_time")
                    or x.get("publishTime")
                    or x.get("published_at")
                    or 0
                ),
                reverse=True,
            )
        except Exception:
            pass

        for i, item in enumerate(data[:count], 1):
            title = (
                item.get("title")
                or item.get("translated_title")
                or item.get("headline")
                or "Untitled"
            )
            source = (
                item.get("source")
                or item.get("source_name")
                or item.get("sourceName")
                or "Unknown"
            )
            published = self._format_time(
                item.get("publishedAt")
                or item.get("timestamp")
                or item.get("publish_time")
                or item.get("publishTime")
                or item.get("published_at")
            )
            summary = (
                item.get("summary")
                or item.get("description")
                or item.get("content")
                or item.get("translated_content")
                or ""
            )
            url = item.get("url") or item.get("page_url") or item.get("pageUrl") or item.get("link") or ""

            lines.append(f"\n{i}. {title}")
            lines.append(f"   Source: {source} | {published}")
            if summary:
                # æˆªæ–­è¿‡é•¿çš„æ‘˜è¦
                truncated = summary[:200] + "..." if len(summary) > 200 else summary
                lines.append(f"   {truncated}")
            if url:
                lines.append(f"   Link: {url}")

        return "\n".join(lines)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # KOL è§‚ç‚¹
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _kol_opinions(self, symbol: str | None, count: int, **_) -> str:
        """èŽ·å– KOL å¯¹ç‰¹å®šå¸ç§çš„è§‚ç‚¹"""
        if not symbol:
            return "Error: 'symbol' is required for kol_opinions (e.g. 'BTC')"

        clean_symbol = self._clean_symbol(symbol)
        raw = await self.hub.followin.get_kol_opinions(symbol=clean_symbol, count=count)
        data, err = self._extract_list_payload(raw)
        if err:
            return f"âŒ Error fetching KOL opinions: {err}"
        if not data:
            return f"ðŸŽ¤ No KOL opinions found for {clean_symbol}."

        lines = [f"ðŸŽ¤ KOL Opinions on {clean_symbol} ({len(data)} results)"]
        lines.append("â•" * 50)

        # ç»Ÿè®¡å¤šç©ºè§‚ç‚¹
        bullish = 0
        bearish = 0
        neutral = 0

        for i, item in enumerate(data[:count], 1):
            author = item.get("author") or item.get("kolName", "Anonymous")
            content = item.get("content") or item.get("text", "")
            sentiment = item.get("sentiment", "neutral")
            followers = item.get("followers", "N/A")
            published = self._format_time(
                item.get("publishedAt")
                or item.get("timestamp")
                or item.get("publish_time")
                or item.get("publishTime")
                or item.get("published_at")
            )

            # ç»Ÿè®¡è§‚ç‚¹æ–¹å‘
            if sentiment in ("bullish", "positive", "long"):
                bullish += 1
                tag = "ðŸŸ¢ Bullish"
            elif sentiment in ("bearish", "negative", "short"):
                bearish += 1
                tag = "ðŸ”´ Bearish"
            else:
                neutral += 1
                tag = "âšª Neutral"

            truncated = content[:180] + "..." if len(content) > 180 else content
            lines.append(f"\n{i}. [{tag}] @{author} ({followers} followers)")
            lines.append(f"   {published}")
            lines.append(f"   {truncated}")

        # è§‚ç‚¹æ±‡æ€»
        lines.append(f"\n{'â”€' * 50}")
        lines.append(f"  Sentiment Summary: ðŸŸ¢ Bullish: {bullish} | ðŸ”´ Bearish: {bearish} | âšª Neutral: {neutral}")
        total = bullish + bearish + neutral
        if total > 0:
            bull_pct = bullish / total * 100
            bear_pct = bearish / total * 100
            lines.append(f"  Bull/Bear Ratio: {bull_pct:.0f}% / {bear_pct:.0f}%")

        return "\n".join(lines)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # çƒ­é—¨è¯é¢˜ï¼ˆä»Šæ—¥æœ€æ–°çƒ­ç‚¹ï¼‰
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _trending_topics(self, count: int, **_) -> str:
        """èŽ·å–å½“å‰åŠ å¯†åœˆçƒ­é—¨è¯é¢˜ï¼ˆä»Šæ—¥æœ€æ–°çƒ­ç‚¹é£Žå‘æ ‡ï¼‰"""
        data = await self.hub.followin.get_trending_topics(count=count)

        if not data:
            return "ðŸ”¥ No trending topics available."

        # API è¿”å›žç»“æž„: {"list": [{"topics": [...]}, ...]}
        # æå–æ‰€æœ‰è¯é¢˜ï¼ˆä¼˜å…ˆä»Šæ—¥ï¼Œç„¶åŽæŒ‰çƒ­åº¦æŽ’åºï¼‰
        all_topics = []
        
        if isinstance(data, dict) and "list" in data:
            # éåŽ†æ‰€æœ‰æ—¥æœŸåˆ†ç»„ï¼Œä¼˜å…ˆå–ç¬¬ä¸€ä¸ªï¼ˆä»Šæ—¥ï¼‰
            for day_group in data.get("list", []):
                topics = day_group.get("topics", [])
                if topics:
                    all_topics.extend(topics)
        elif isinstance(data, list):
            # å¦‚æžœç›´æŽ¥è¿”å›žåˆ—è¡¨ï¼Œä½¿ç”¨å®ƒ
            all_topics = data
        else:
            # å°è¯•ä»Žé”™è¯¯å“åº”ä¸­æå–
            if isinstance(data, dict) and "error" in data:
                return f"âŒ Error fetching trending topics: {data.get('error')}"
            all_topics = []

        if not all_topics:
            return "ðŸ”¥ No trending topics available."

        # æŒ‰çƒ­åº¦æŽ’åºï¼ˆå¦‚æžœ API æ²¡æœ‰æŽ’åºï¼‰
        try:
            all_topics.sort(key=lambda x: x.get("heat", 0) or 0, reverse=True)
        except Exception:
            pass

        # é™åˆ¶è¿”å›žæ•°é‡
        topics_to_show = all_topics[:count]

        lines = [f"ðŸ”¥ ä»Šæ—¥æœ€æ–°çƒ­ç‚¹ï¼ˆçƒ­é—¨é£Žå‘æ ‡ï¼‰"]
        lines.append("â•" * 60)
        lines.append(f"å…± {len(topics_to_show)} ä¸ªçƒ­é—¨è¯é¢˜\n")

        for i, topic in enumerate(topics_to_show, 1):
            title = topic.get("title") or topic.get("topic", "Unknown")
            heat = topic.get("heat", 0) or 0
            source_count = topic.get("source_count", 0) or 0
            desc = topic.get("desc", "") or topic.get("description", "")
            
            # æå–æ ‡ç­¾ï¼ˆå¸ç§ï¼‰
            tags = topic.get("tags", [])
            tag_symbols = []
            if isinstance(tags, list):
                for tag in tags:
                    if isinstance(tag, dict):
                        symbol = tag.get("symbol") or tag.get("name", "")
                        if symbol:
                            tag_symbols.append(symbol)
            
            # æå–åŽŸå› ï¼ˆå¦‚ "KOLçƒ­è®®"ï¼‰
            reasons = topic.get("reasons", [])
            reason_texts = []
            if isinstance(reasons, list):
                for reason in reasons:
                    if isinstance(reason, dict):
                        text = reason.get("text", "")
                        if text:
                            reason_texts.append(text)

            # æ ¼å¼åŒ–çƒ­åº¦ï¼ˆå¤§æ•°å­—ç”¨ K/M è¡¨ç¤ºï¼‰
            heat_str = self._format_heat(heat)
            
            lines.append(f"{i}. {title}")
            
            # æ˜¾ç¤ºæ ‡ç­¾
            if tag_symbols:
                tag_str = ", ".join(tag_symbols[:3])  # æœ€å¤šæ˜¾ç¤º3ä¸ª
                if len(tag_symbols) > 3:
                    tag_str += f" +{len(tag_symbols) - 3}"
                lines.append(f"   ðŸ·ï¸  {tag_str}")
            
            # æ˜¾ç¤ºçƒ­åº¦å’Œæ¥æºæ•°
            info_parts = [f"çƒ­åº¦: {heat_str}"]
            if source_count > 0:
                info_parts.append(f"æ¥æº: {source_count}")
            if reason_texts:
                info_parts.append(f"åŽŸå› : {', '.join(reason_texts)}")
            lines.append(f"   {' | '.join(info_parts)}")
            
            # æ˜¾ç¤ºæè¿°
            if desc:
                truncated = desc[:200] + "..." if len(desc) > 200 else desc
                lines.append(f"   {truncated}")
            
            lines.append("")  # ç©ºè¡Œåˆ†éš”

        return "\n".join(lines)
    
    @staticmethod
    def _format_heat(heat: int | float) -> str:
        """æ ¼å¼åŒ–çƒ­åº¦æ•°å­—ï¼ˆå¦‚ 108172 -> 108Kï¼‰"""
        try:
            heat_num = float(heat)
            if heat_num >= 1_000_000:
                return f"{heat_num / 1_000_000:.1f}M"
            elif heat_num >= 1_000:
                return f"{heat_num / 1_000:.1f}K"
            else:
                return str(int(heat_num))
        except Exception:
            return str(heat)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # å¸ç§æ–°é—»
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _coin_news(self, symbol: str | None, count: int, **_) -> str:
        """èŽ·å–ç‰¹å®šå¸ç§ç›¸å…³æ–°é—»"""
        if not symbol:
            return "Error: 'symbol' is required for coin_news (e.g. 'BTC')"

        clean_symbol = self._clean_symbol(symbol)
        raw = await self.hub.followin.get_coin_news(symbol=clean_symbol, count=count)
        data, err = self._extract_list_payload(raw)
        if err:
            return f"âŒ Error fetching coin news: {err}"
        if not data:
            return f"ðŸ“° No recent news for {clean_symbol}."

        lines = [f"ðŸ“° News for {clean_symbol} ({len(data)} results)"]
        lines.append("â•" * 50)

        for i, item in enumerate(data[:count], 1):
            title = (
                item.get("title")
                or item.get("translated_title")
                or item.get("headline")
                or "Untitled"
            )
            source = (
                item.get("source")
                or item.get("source_name")
                or item.get("sourceName")
                or "Unknown"
            )
            published = self._format_time(
                item.get("publishedAt")
                or item.get("timestamp")
                or item.get("publish_time")
                or item.get("publishTime")
                or item.get("published_at")
            )
            summary = (
                item.get("summary")
                or item.get("description")
                or item.get("content")
                or item.get("translated_content")
                or ""
            )
            impact = item.get("impact", "")
            url = item.get("url") or item.get("page_url") or item.get("pageUrl") or item.get("link") or ""

            lines.append(f"\n{i}. {title}")
            lines.append(f"   Source: {source} | {published}")
            if impact:
                lines.append(f"   Impact: {impact}")
            if summary:
                truncated = summary[:200] + "..." if len(summary) > 200 else summary
                lines.append(f"   {truncated}")
            if url:
                lines.append(f"   Link: {url}")

        return "\n".join(lines)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # çªå‘æ¶ˆæ¯
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _breaking_news(self, count: int, **_) -> str:
        """èŽ·å–çªå‘æ¶ˆæ¯ï¼ˆbwenews ç¼“å­˜ + Followin å¿«è®¯ï¼‰"""
        # çªå‘æ¶ˆæ¯æ¥è‡ª Followin å¿«è®¯ (flash news) + bwenews WS ç¼“å­˜
        raw = await self.hub.followin.get_flash_news(count=count)
        data, err = self._extract_list_payload(raw)
        if err:
            return f"âŒ Error fetching breaking news: {err}"
        if not data:
            return "âš¡ No breaking news at the moment."

        lines = [f"âš¡ Breaking News ({len(data)} alerts)"]
        lines.append("â•" * 50)

        for i, item in enumerate(data[:count], 1):
            title = item.get("title") or item.get("content", "")
            published = self._format_time(
                item.get("publishedAt")
                or item.get("timestamp")
                or item.get("publish_time")
                or item.get("publishTime")
                or item.get("published_at")
            )
            urgency = item.get("urgency", "normal")

            # æ ¹æ®ç´§æ€¥ç¨‹åº¦æ·»åŠ æ ‡è®°
            if urgency == "high":
                prefix = "ðŸš¨"
            elif urgency == "medium":
                prefix = "âš¡"
            else:
                prefix = "ðŸ“¢"

            truncated = title[:250] + "..." if len(title) > 250 else title
            lines.append(f"\n{prefix} [{published}]")
            lines.append(f"   {truncated}")

        return "\n".join(lines)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # å·¥å…·æ–¹æ³•
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @staticmethod
    def _clean_symbol(symbol: str) -> str:
        """æ¸…ç†å¸ç§ç¬¦å·ï¼Œæå–åŸºç¡€å¸ç§"""
        return symbol.split("/")[0].split(":")[0].upper()

    @staticmethod
    def _format_time(ts: Any) -> str:
        """å°†æ—¶é—´æˆ³æ ¼å¼åŒ–ä¸ºå¯è¯»å­—ç¬¦ä¸²"""
        if ts is None:
            return "Unknown time"
        try:
            if isinstance(ts, (int, float)):
                # è‡ªåŠ¨æ£€æµ‹ç§’ vs æ¯«ç§’æ—¶é—´æˆ³
                if ts > 1e12:
                    ts = ts / 1000
                dt = datetime.fromtimestamp(ts, tz=timezone.utc)
            elif isinstance(ts, str):
                dt = datetime.fromisoformat(ts.replace("Z", "+00:00"))
            else:
                return str(ts)

            # è®¡ç®—ç›¸å¯¹æ—¶é—´
            now = datetime.now(timezone.utc)
            delta = now - dt
            seconds = int(delta.total_seconds())

            if seconds < 60:
                return "just now"
            elif seconds < 3600:
                return f"{seconds // 60}m ago"
            elif seconds < 86400:
                return f"{seconds // 3600}h ago"
            else:
                return dt.strftime("%Y-%m-%d %H:%M UTC")
        except Exception:
            return str(ts)
